---
title: "Model covariates"
author: "Katy Gaythorpe"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes: 
- \usepackage{placeins}
output: 
  pdf_document:
    df_print: "kable"
---

This document outlines the methods used to choose the covariates in the generalised linear model of yellow fever occurrence.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


```{r libraries}
library(KsetupR)

library(dplyr)
library(magrittr)
library(corrplot)
library(ggplot2)
library(tidyr)
library(caret)
library(MASS)
library(bestglm)

source('Functions/data_launch.R')
source("Functions/temp_suit.R")
```

We begin by loading the data `dat` which consists of the outcome variable `cases_or_outbreaks` and all the environmental data for each admin one unit.


```{r load_data}

Env_Table_path <- "../Data/Environment/global_dat"

  filename = get_latest_file(path = Env_Table_path, pattern = "dat_wes_mosquito_daniel")
  
  dat = read.csv(filename, stringsAsFactors = FALSE)
  
  dat %<>% mutate_at(.vars = c(5,6,8:18, 20:ncol(dat)), as.numeric)
  

# remove missing entries and year column
dat %<>% dplyr::select(-year)
dat %<>% filter( is.finite(MIR.max))
dat %<>% filter(!is.na(temp_mean))
dat %<>% mutate(continent = ifelse(adm0 %in% c("CIV", "STP"),
                                   "Africa", continent)) 


# make extra elements and normalise
dat <- adjust_env_dat(dat)

dat[dat==Inf] = NA
dat = dat[, !apply(dat, 2, anyNA)]

```

We may then begin choosing the covariates. First we fetch the list of all covariates.

```{r covar_to_test}
#get full list of covariates
covar_to_test <- names(dat)[9:(ncol(dat))]

#remove those that will be included anyway/ not relevant
covar_to_test <- covar_to_test[grep("surv.qual", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("LC_dom", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("risk", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("population", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("aggregate", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("adm05", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("continent", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("dtp", covar_to_test, invert = TRUE)]

# remove max min 
covar_to_test <- covar_to_test[grep("temp_max", covar_to_test, invert = TRUE)]
covar_to_test <- covar_to_test[grep("temp_suit_max", covar_to_test, invert = TRUE)]

covar_to_test <- covar_to_test[grep("genus", covar_to_test, invert = TRUE)]

as.data.frame(covar_to_test)
saveRDS(covar_to_test, "covariates.rds")
```
Now we remove those covariates that are not significantly associated with the data. This is done through fitting univariate models and examining the pvalues.

```{r fit_univariate}

mod <- list()
pvalues <- rep(NA, length(covar_to_test))
coeffs <- rep(NA, length(covar_to_test))
BICs <- rep(NA, length(covar_to_test))
for(i in 1:length(covar_to_test)){
  mod[[i]] <- glm( paste0("cases_or_outbreaks~",covar_to_test[i]), 
           data = dat, family=binomial(link="cloglog"))
  
  pvalues[i] <- coef(summary(mod[[i]]))[,4]
  coeffs[i] <- coef(summary(mod[[i]]))[,1]
  BICs[i] <- BIC(mod[[i]])
}

df <-  data.frame(covariate = covar_to_test, 
                        pvalue = pvalues, 
                        coeff = coeffs,
                        BIC = BICs) %>% 
               arrange(-pvalues)

df

df %<>% filter(pvalue < 0.1)

covar_to_test = as.character(df$covariate)

```

We examine covariates that are highly correlated.

```{r remove_cor, fig.height=12, fig.width=12, fig.cap="Heatmap of parameter correlatons."}

reduced_dat <-  dat[, covar_to_test]

reduced_dat_cor <-  cor(reduced_dat)

heatmap(reduced_dat_cor, keep.dendro = TRUE)

cor_df <- as.data.frame(reduced_dat_cor) 
cor_df$param1 <- rownames(cor_df)
cor_df %<>% gather(param2, correlation, -param1)

```

\FloatBarrier

We find that some covariates are highly correlated. As such, we group these into clusters where the absolute piecewise correlation is above 0.75.

```{r clusters, fig.height=12, fig.width=10}
x <- as.dist( 1-abs(cor(na.omit(dat[, na.omit(covar_to_test)]))))
out <- hclust(x)

df <-  data.frame(param1 = unique(cor_df$param1))

i = length(covar_to_test)
pairwise_cor = 1
while(i >1 & pairwise_cor>0.75){
  i <- i-1
  
  y <- cutree(out, k = i)
  
  tmp = data.frame(param1 = names(y), as.numeric(y))
  names(tmp)[2] = paste0("cluster", i)
  
  df %<>% left_join(tmp)
  
  
  for(c in unique(y)){
    cluster_parm = df$param1[df[,paste0("cluster", i)] == c]
    if(length(cluster_parm)>1){
      out_cor = cor(as.matrix(dat[, as.character(cluster_parm)]))
      pairwise_cor = min(min(out_cor[out_cor<1]), pairwise_cor)
    }
  }
  
}

# final is i-1
df_out = df[, c(1, (ncol(df)-1))]
names(df_out)[2] = "cluster"

df_out %>% arrange(cluster)
```

In order to reduce the number of covariates to test, we may choose those covariates in each cluster that are most correlated with our outcome variable. 

```{r cor with cas}

df_out %<>% mutate(cor_with_case = NA)

for(i in 1:nrow(df_out)){
  df_out$cor_with_case[i] = abs(cor(dat[, c("cases_or_outbreaks", 
                                            as.character(df_out$param1[i]))])[1,2])
}

df_covar <-  df_out %>% 
  group_by(cluster) %>% 
  arrange(-cor_with_case) %>% 
  summarise(param1 = first(param1))

covar_to_test = as.character(df_covar$param1)
```

We use the `stepAIC` function from the `MASS` package to step through model possibilities. This uses BIC as a criteria to assess the inclusion of each model covariate.

```{r stepAIC}

dat_subs <-  dat[, c("cases_or_outbreaks" ,covar_to_test)] # subset 

#use stepAIC to get list of important covariates
alt_mod <-  MASS::stepAIC(glm("cases_or_outbreaks~.", data = dat_subs, 
                            family=binomial(link="cloglog")), 
                        trace = FALSE,
                        k = log(nrow(dat_subs))) #turning into BIC
summary(alt_mod)

# remove those that are not significant
pvalues <- coef(summary(alt_mod))[,4]

parm_out <- names(head(sort(pvalues), 16)) #get 15 most significant
parm_out <- parm_out[grep("(Intercept)", parm_out, invert = T)] # remove intercept

as.data.frame(parm_out)

```

Finally, we use the `bestglm` function from `bestglm` to find the top 20 models from this subset of covariates. This uses the complete enumeration algorithm.

```{r bestglm, eval = T}


dat_subs = dat[, c(parm_out, "cases_or_outbreaks")]

out = bestglm(Xy = dat_subs, 
        family = binomial(link="cloglog"),
        #nvmax = 5,
        TopModels = 20)

out$BestModel

write.csv(out$BestModels, "bestglm_A1.csv", row.names = FALSE)
```

# Land cover types

Here is a reminder of the land cover types and their abbreviations.

```{r, echo=FALSE}

data.frame( Name = c("Evergreen Needleleaf Forests",
                     "Evergreen Broadleaf Forests",
                     "Deciduous Needleleaf Forests",
                     "Deciduous Broadleaf Forests",
                     "Mixed Forests",
                     "Closed Shrublands",
                     "Open Shrublands",
                     "Woody Savannas",
                     "Savannas",
                     "Grasslands",
                     "Permanent Wetlands",
                     "Croplands",
                     "Urban and Built-up Lands",
                     "Cropland/Natural Vegetation Mosaics",
                     "Permanent Snow and Ice",
                     "Barren",
                     "Water Bodies"),
Landcover = c(1:16, 17) )

```